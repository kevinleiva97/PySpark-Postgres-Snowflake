{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "985f11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "from snowflake.connector.pandas_tools import pd_writer\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import snowflake.connector\n",
    "from snowflake.connector import pandas_tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd0255d",
   "metadata": {},
   "source": [
    "# Prep of the Env\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e292a76",
   "metadata": {},
   "source": [
    "## Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "418c8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"GetcsvData\").getOrCreate()\n",
    "path_csv = \"/Users/kevinleiva/Desktop/Big_data/data.csv\"\n",
    "#Postgres\n",
    "engine = create_engine('postgresql://insert_data:Pass@localhost:5432/postgres')\n",
    "#snowflake\n",
    "pass = ''\n",
    "conn_sf = snowflake.connector.connect(\n",
    "    user= 'kevin_leiva_sbx',\n",
    "    password= pass,\n",
    "    account= 'ht48847.canada-central.azure',\n",
    "    warehouse='COMPUTE_WH',\n",
    "    database='TEST_KL_STAGIN_DB',\n",
    "    schema='PUBLIC'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7776bcc6",
   "metadata": {},
   "source": [
    "## Load Data from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c5a789f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5985364"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(path=path_csv,header='True')\n",
    "df2 = pd.read_csv(path_csv)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34ed10",
   "metadata": {},
   "source": [
    "##  Ingest data into postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26bb4fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.to_sql('dataFrame', con=engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05d2bb9",
   "metadata": {},
   "source": [
    "## Create table in SnowFlake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "5907f0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x31501e8f0>"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_sf.cursor().execute(\"CREATE or replace TABLE dataFrame(index string,anzsic06 string,Area string,year string ,geo_count string ,ec_count string)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3dc14b",
   "metadata": {},
   "source": [
    "# Start the ELT from Postgres into SnowFlake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f140737",
   "metadata": {},
   "source": [
    "## get data from Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "5aa98a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.read_sql('select * from \"dataFrame\" ', engine) #209268"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d171b40f",
   "metadata": {},
   "source": [
    "## Convert Pandas dataframe to spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "4bd37900",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpp = spark.createDataFrame(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "e6c41373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/10 22:01:48 WARN TaskSetManager: Stage 128 contains a task of very large size (22452 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5985364"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfpp.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8bfa04",
   "metadata": {},
   "source": [
    "## Export from Spark Dataframe to a multiple csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "9ce5e577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfpp.write.mode(\"ignore\").csv(\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fadd865",
   "metadata": {},
   "source": [
    "### testing the small chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "96de5e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/kevinleiva/Desktop/Big_data/output/*'\n",
    "pd_test = spark.read.option(\"delimiter\", \",\").option(\"header\", False).csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "cd854d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5985364"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "8753647c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 148:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(_c0='747518', _c1='M696', _c2='C07602', _c3='2020', _c4='669', _c5='400'),\n",
       " Row(_c0='747519', _c1='M696', _c2='C07603', _c3='2020', _c4='561', _c5='860')]"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_path = '/Users/kevinleiva/Desktop/Big_data/output/*'\n",
    "df_test = spark.read.option(\"delimiter\", \",\").option(\"header\", False).csv(full_path)\n",
    "df_test.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "62d12b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+----+---+---+\n",
      "|    _c0| _c1|    _c2| _c3|_c4|_c5|\n",
      "+-------+----+-------+----+---+---+\n",
      "|1496064|H451|A166300|2017|  9|170|\n",
      "|1496065|H451|A166500|2017|  3| 35|\n",
      "+-------+----+-------+----+---+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe3d0c3",
   "metadata": {},
   "source": [
    "## Insert the Data into Snowflake using Put and Copy into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "a1e26a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x2a2a46a40>"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_sf.cursor().execute(\"truncate table dataframe\")\n",
    "conn_sf.cursor().execute(f\"PUT file:////Users/kevinleiva/Desktop/Big_data/output/* @%dataFrame\")\n",
    "conn_sf.cursor().execute(\"COPY INTO dataFrame\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
